<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title> publications | Chao Zhou </title>
  <meta name="author" content="Chao Zhou">
  <meta name="description"
    content="publications by categories in reversed chronological order. generated by jekyll-scholar.">
  <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">
  <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css"
    integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">
  <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5">
  <link defer rel="stylesheet" type="text/css"
    href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap">
  <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99"
    media="" id="highlight_theme_light">
  <link rel="shortcut icon"
    href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
  <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
  <link rel="canonical" href="https://chaoedisonzhouucl.github.io/publications/">
  <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script>
  <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca"
    media="none" id="highlight_theme_dark">
  <script>initTheme();</script>
</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-FM8ZQ1G550"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-FM8ZQ1G550');
</script>

<body class="fixed-top-nav ">
  <header>
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation">
      <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span
            class="font-weight-bold">Chao</span> Zhou </a> <button class="navbar-toggler collapsed ml-auto"
          type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false"
          aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span
            class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span
            class="icon-bar bottom-bar"></span> </button>
        <div class="collapse navbar-collapse text-right" id="navbarNav">
          <ul class="navbar-nav ml-auto flex-nowrap">
            <li class="nav-item "> <a class="nav-link" href="/">about </a> </li>
            <!-- <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> -->
            <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span
                  class="sr-only">(current)</span> </a> </li>
            <!-- <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> -->
            <!-- <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> -->
            <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li>
            <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li>
            <!-- <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> -->
            <li class="nav-item dropdown active"> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown"
                role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus <span
                  class="sr-only">(current)</span> </a>
              <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a
                  class="dropdown-item active" href="/publications/">publications</a>
                <!-- <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/">projects</a> -->
                <!-- <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> -->
              </div>
            </li>
            <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon"
                  id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i
                  class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li>
          </ul>
        </div>
      </div>
    </nav> <progress id="progress" value="0">
      <div class="progress-container"> <span class="progress-bar"></span> </div>
    </progress>
  </header>
  <div class="container mt-5" role="main">
    <div class="post">
      <header class="post-header">
        <h1 class="post-title">publications</h1>
        <p class="post-description">publications by categories in reversed chronological order. generated by
          jekyll-scholar.</p>
      </header>
      <article>
        <div class="publications">
          <h2 class="bibliography">2023</h2>
          <ol class="bibliography">
            <li>
              <div class="row">
                <div class="col-sm-2 abbr"> <abbr class="badge">Conference</abbr>
                </div>
                <div id="10.1109/ICIP49359.2023.10222918" class="col-sm-8">
                  <div class="title">BITS-Net: Blind Image Transparency Separation Network
                  </div>
                  <div class="author">
                    <em>C. Zhou</em>, <a href="https://scholar.google.com/citations?user=gDZJTy0AAAAJ&hl=en"
                      rel="external nofollow noopener" target="_blank">Z. Lyu</a>, and
                    <a href="https://scholar.google.co.uk/citations?user=Fmjz3bYAAAAJ&hl=en"
                      rel="external nofollow noopener" target="_blank">M. R. D. Rodrigues</a>
                  </div>
                  <div class="periodical"> in <em>IEEE International Conference on Image Processing (ICIP)</em>, Kuala
                    Lumpur, Malaysia, 2023, pp. 375-379, doi: 10.1109/ICIP49359.2023.10222918.</div>

                  <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                    <a href="https://ieeexplore.ieee.org/abstract/document/10222918" class="btn btn-sm z-depth-0"
                      role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a
                      href="https://github.com/ChaoEdisonZhouUCL/BITS-NET" class="btn btn-sm z-depth-0" role="button"
                      rel="external nofollow noopener" target="_blank">Code</a>
                  </div>
                  <div class="abstract hidden">
                    <p>This research presents a new approach for blind single-image transparency separation, a
                      significant challenge in image processing. The proposed framework divides the task into two
                      parallel processes: feature separation and image reconstruction. The feature separation task
                      leverages two deep image prior (DIP) networks to recover two distinct layers. An exclusion loss
                      and deep feature separation loss are used to decompose features. For the image reconstruction
                      task, we minimize the difference between the mixed image and the re-mixed image while also
                      incorporating a regularizer to impose natural priors on each layer. Our results indicate that our
                      method performs comparably or outperforms state-of-the-art approaches when tested on various image
                      datasets.</p>
                  </div>
                </div>
              </div>
            </li>
            <li>
              <div class="row">
                <div class="col-sm-2 abbr"> <abbr class="badge">Journal</abbr>
                </div>
                <div id="10.1109/TNNLS.2023.3294714" class="col-sm-8">
                  <div class="title">Hyperspectral Blind Unmixing Using a Double Deep Image Prior
                  </div>
                  <div class="author">
                    <em>C. Zhou</em>, and
                    <a href="https://scholar.google.co.uk/citations?user=Fmjz3bYAAAAJ&hl=en"
                      rel="external nofollow noopener" target="_blank">M. R. D. Rodrigues</a>
                  </div>
                  <div class="periodical"> in <em>IEEE Transactions on Neural Networks and Learning
                      Systems</em>, doi: 10.1109/TNNLS.2023.3294714.</div>

                  <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                    <a href="https://ieeexplore.ieee.org/abstract/document/10225313" class="btn btn-sm z-depth-0"
                      role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a
                      href="https://github.com/ChaoEdisonZhouUCL/BUDDIP-TNNLS" class="btn btn-sm z-depth-0"
                      role="button" rel="external nofollow noopener" target="_blank">Code</a>
                  </div>
                  <div class="abstract hidden">
                    <p>With the rise of machine learning, hyperspectral image (HSI) unmixing
                      problems have been tackled using learning-based methods. However, physically
                      meaningful unmixing results are not guaranteed without proper guidance. In
                      this work, we propose an unsupervised framework inspired by deep image prior
                      (DIP) that can be used for both linear and nonlinear blind unmixing models.
                      The framework consists of three modules: 1) an Endmember estimation module
                      using DIP (EDIP); 2) an Abundance estimation module using DIP (ADIP); and 3)
                      a mixing module (MM). EDIP and ADIP modules generate endmembers and
                      abundances, respectively, while MM produces a reconstruction of the HSI
                      observations based on the postulated unmixing model. We introduce a
                      composite loss function that applies to both linear and nonlinear unmixing
                      models to generate meaningful unmixing results. In addition, we propose an
                      adaptive loss weight strategy for better unmixing results in nonlinear
                      mixing scenarios. The proposed methods outperform state-of-the-art unmixing
                      algorithms in extensive experiments conducted on both synthetic and real
                      datasets.</p>
                  </div>
                </div>
              </div>
            </li>
            <li>
              <div class="row">
                <div class="col-sm-2 abbr"> <abbr class="badge">Journal</abbr>
                </div>
                <div id="10.1109/TIP.2023.3275872" class="col-sm-8">
                  <div class="title">Image Separation With Side Information: A Connected Auto-Encoders Based Approach
                  </div>
                  <div class="author">
                    <a href="https://scholar.google.com/citations?user=T_KI5M4AAAAJ&hl=en"
                      rel="external nofollow noopener" target="_blank">W. Pu</a>, <a
                      href="https://scholar.google.com/citations?user=tEwLrjIAAAAJ&hl=en"
                      rel="external nofollow noopener" target="_blank">B Sober</a>, N. Daly, <em>C. Zhou</em>, <a
                      href="https://scholar.google.com/citations?user=XrD27MoAAAAJ&hl=en"
                      rel="external nofollow noopener" target="_blank">Z.
                      Sabetsarvestani</a>, C. Higgitt, <a
                      href="https://scholar.google.com/citations?user=K83ZJJUAAAAJ&hl=en"
                      rel="external nofollow noopener" target="_blank">I. Daubechies</a>, and <a
                      href="https://scholar.google.co.uk/citations?user=Fmjz3bYAAAAJ&hl=en"
                      rel="external nofollow noopener" target="_blank">M. R. D. Rodrigues</a>
                  </div>
                  <div class="periodical"> in <em>IEEE Transactions on Image Processing</em>, vol. 32, pp. 2931-2946,
                    2023, doi: 10.1109/TIP.2023.3275872.</div>

                  <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                    <a href="https://ieeexplore.ieee.org/abstract/document/10129219" class="btn btn-sm z-depth-0"
                      role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a
                      href="https://github.com/ART-ICT/Xray_Separation_2RGB" class="btn btn-sm z-depth-0" role="button"
                      rel="external nofollow noopener" target="_blank">Code</a>
                  </div>
                  <div class="abstract hidden">
                    <p>X-radiography (X-ray imaging) is a widely used imaging technique in art investigation. It can
                      provide information about the condition of a painting as well as insights into an artist’s
                      techniques and working methods, often revealing hidden information invisible to the naked eye.
                      X-radiograpy of double-sided paintings results in a mixed X-ray image and this paper deals with
                      the problem of separating this mixed image. Using the visible color images (RGB images) from
                      each side of the painting, we propose a new Neural Network architecture, based upon ‘connected’
                      auto-encoders, designed to separate the mixed X-ray image into two simulated X-ray images
                      corresponding to each side. This connected auto-encoders architecture is such that the encoders
                      are based on convolutional learned iterative shrinkage thresholding algorithms (CLISTA) designed
                      using algorithm unrolling techniques, whereas the decoders consist of simple linear
                      convolutional layers; the encoders extract sparse codes from the visible image of the front and
                      rear paintings and mixed X-ray image, whereas the decoders reproduce both the original RGB
                      images and the mixed X-ray image. The learning algorithm operates in a totally self-supervised
                      fashion without requiring a sample set that contains both the mixed X-ray images and the
                      separated ones. The methodology was tested on images from the double-sided wing panels of the
                      Ghent Altarpiece, painted in 1432 by the brothers Hubert and Jan van Eyck. These tests show that
                      the proposed approach outperforms other state-of-the-art X-ray image separation methods for art
                      investigation applications.</p>
                  </div>
                </div>
              </div>
            </li>
          </ol>
          <h2 class="bibliography">2022</h2>
          <ol class="bibliography">
            <li>
              <div class="row">
                <div class="col-sm-2 abbr"> <abbr class="badge">Conference</abbr>
                </div>
                <div id="10.1109/ICASSP43922.2022.9747545" class="col-sm-8">
                  <div class="title">Blind Unmixing Using A Double Deep Image Prior
                  </div>
                  <div class="author">
                    <em>C. Zhou</em>, and
                    <a href="https://scholar.google.co.uk/citations?user=Fmjz3bYAAAAJ&hl=en"
                      rel="external nofollow noopener" target="_blank">M. R. D. Rodrigues</a>
                  </div>
                  <div class="periodical"> in <em>IEEE International Conference on Acoustics, Speech and Signal
                      Processing (ICASSP)</em>, Singapore, Singapore, 2022, pp. 1665-1669, doi:
                    10.1109/ICASSP43922.2022.9747545.</div>

                  <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                    <a href="https://ieeexplore.ieee.org/abstract/document/9747545" class="btn btn-sm z-depth-0"
                      role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a
                      href="https://github.com/ChaoEdisonZhouUCL/BUDDIP-ICASSP-2022" class="btn btn-sm z-depth-0"
                      role="button" rel="external nofollow noopener" target="_blank">Code</a>
                  </div>
                  <div class="abstract hidden">
                    <p>In this paper, we propose a novel network structure to solve the blind hyperspectral unmixing
                      problem using a double Deep Image Prior (DIP). In particular, the blind unmixing problem involves
                      two sub-problems: endmember estimation and abundance estimation. We, therefore, propose two
                      sub-networks, endmember estimation DIP (EDIP) and abundance estimation DIP (ADIP), to generate the
                      estimation of endmembers and estimation of corresponding abundances respectively. The overall
                      network is then constructed by assembling these two sub-networks. The network is trained in an
                      end-to-end manner by minimizing a novel composite loss function. The experiments on synthetic and
                      real datasets show the effectiveness of the proposed method over state-of-art unmixing methods.
                    </p>
                  </div>
                </div>
              </div>
            </li>
          </ol>
          <h2 class="bibliography">2021</h2>
          <ol class="bibliography">
            <li>
              <div class="row">
                <div class="col-sm-2 abbr"> <abbr class="badge">Journal</abbr>
                </div>
                <div id="10.1109/TGRS.2021.3136336" class="col-sm-8">
                  <div class="title">ADMM-Based Hyperspectral Unmixing Networks for Abundance and Endmember Estimation
                  </div>
                  <div class="author">
                    <em>C. Zhou</em>, and
                    <a href="https://scholar.google.co.uk/citations?user=Fmjz3bYAAAAJ&hl=en"
                      rel="external nofollow noopener" target="_blank">M. R. D. Rodrigues</a>
                  </div>
                  <div class="periodical"> in <em>IEEE Transactions on Geoscience and Remote Sensing</em>, vol. 60, pp.
                    1-18, 2022, Art no. 5520018, doi: 10.1109/TGRS.2021.3136336. </div>

                  <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                    <a href="https://ieeexplore.ieee.org/abstract/document/9654204" class="btn btn-sm z-depth-0"
                      role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a
                      href="https://github.com/ChaoEdisonZhouUCL/UADMMNet" class="btn btn-sm z-depth-0" role="button"
                      rel="external nofollow noopener" target="_blank">Code</a>
                  </div>
                  <div class="abstract hidden">
                    <p>Hyperspectral image (HSI) unmixing is an increasingly studied problem in various areas, including
                      remote sensing. It has been tackled using both physical model-based approaches and more recently
                      machine learning-based ones. In this article, we propose a new HSI unmixing algorithm combining
                      both model- and learning-based techniques, based on algorithm unrolling approaches, delivering
                      improved unmixing performance. Our approach unrolls the alternating direction method of
                      multipliers (ADMMs) solver of a constrained sparse regression problem underlying a linear mixture
                      model. We then propose a neural network structure for abundance estimation that can be trained
                      using supervised learning techniques based on a new composite loss function. We also propose
                      another neural network structure for blind unmixing that can be trained using unsupervised
                      learning techniques. Our proposed networks are also shown to possess a lighter and richer
                      structure containing less learnable parameters and more skip connections compared with other
                      competing architectures. Extensive experiments show that the proposed methods can achieve much
                      faster convergence and better performance even with a very small training dataset size when
                      compared with other unmixing methods, such as model-inspired neural network for abundance
                      estimation (MNN-AE), model-inspired neural network for blind unmixing (MNN-BU), unmixing using
                      deep image prior (UnDIP), and endmember-guided unmixing network (EGU-Net).</p>
                  </div>
                </div>
              </div>
            </li>
            <li>
              <div class="row">
                <div class="col-sm-2 abbr"> <abbr class="badge">Journal</abbr>
                </div>
                <div id="arXiv:2110.10391" class="col-sm-8">
                  <div class="title">Robust lEarned Shrinkage-Thresholding (REST): Robust unrolling for sparse recover
                  </div>
                  <div class="author">
                    <a href="https://scholar.google.com/citations?user=T_KI5M4AAAAJ&hl=en"
                      rel="external nofollow noopener" target="_blank">W. Pu</a>, <em>C. Zhou</em>, <a
                      href="https://scholar.google.com/citations?user=vyX6kpwAAAAJ&hl=en"
                      rel="external nofollow noopener" target="_blank">Y. C. Eldar</a>, and <a
                      href="https://scholar.google.co.uk/citations?user=Fmjz3bYAAAAJ&hl=en"
                      rel="external nofollow noopener" target="_blank">M. R. D. Rodrigues</a>
                  </div>
                  <div class="periodical"> in <em>https://doi.org/10.48550/arXiv.2110.10391</em>. </div>
                  <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                    <a href="https://arxiv.org/abs/2110.10391" class="btn btn-sm z-depth-0" role="button"
                      rel="external nofollow noopener" target="_blank">PDF</a>
                  </div>
                  <div class="abstract hidden">
                    <p>In this paper, we consider deep neural networks for solving inverse problems that are robust to
                      forward model mis-specifications. Specifically, we treat sensing problems with model mismatch
                      where one wishes to recover a sparse high-dimensional vector from low-dimensional observations
                      subject to uncertainty in the measurement operator. We then design a new robust deep neural
                      network architecture by applying algorithm unfolding techniques to a robust version of the
                      underlying recovery problem. Our proposed network - named Robust lEarned Shrinkage-Thresholding
                      (REST) - exhibits an additional normalization processing compared to Learned Iterative
                      Shrinkage-Thresholding Algorithm (LISTA), leading to reliable recovery of the signal under
                      sample-wise varying model mismatch. The proposed REST network is shown to outperform
                      state-of-the-art model-based and data-driven algorithms in both compressive sensing and radar
                      imaging problems wherein model mismatch is taken into consideration.</p>
                  </div>
                </div>
              </div>
            </li>
            <li>
              <div class="row">
                <div class="col-sm-2 abbr"> <abbr class="badge">Conference</abbr>
                </div>
                <div id="10.1109/ICASSP39728.2021.9414141" class="col-sm-8">
                  <div class="title">REST: Robust lEarned Shrinkage-Thresholding Network Taming Inverse Problems with
                    Model Mismatch
                  </div>
                  <div class="author">
                    <a href="https://scholar.google.com/citations?user=T_KI5M4AAAAJ&hl=en"
                      rel="external nofollow noopener" target="_blank">W. Pu</a>, <em>C. Zhou</em>, <a
                      href="https://scholar.google.com/citations?user=vyX6kpwAAAAJ&hl=en"
                      rel="external nofollow noopener" target="_blank">Y. C. Eldar</a>, and <a
                      href="https://scholar.google.co.uk/citations?user=Fmjz3bYAAAAJ&hl=en"
                      rel="external nofollow noopener" target="_blank">M. R. D. Rodrigues</a>
                  </div>
                  <div class="periodical"> in <em>IEEE International Conference on Acoustics, Speech and Signal
                      Processing (ICASSP)</em>, Toronto, ON, Canada, 2021, pp. 2885-2889, doi:
                    10.1109/ICASSP39728.2021.9414141.</div>

                  <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                    <a href="https://ieeexplore.ieee.org/abstract/document/9414141" class="btn btn-sm z-depth-0"
                      role="button" rel="external nofollow noopener" target="_blank">PDF</a>
                  </div>
                  <div class="abstract hidden">
                    <p>We consider compressive sensing problems with model mismatch where one wishes to recover a sparse
                      high-dimensional vector from low-dimensional observations subject to uncertainty in the
                      measurement operator. In particular, we design a new robust deep neural network architecture by
                      applying algorithm unfolding techniques to a robust version of the underlying recovery problem.
                      Our proposed network –named Robust lErned Shrinkage-Thresholding (REST) –exhibits additional
                      features including enlarged number of parameters and normalization processing compared to
                      state-of-the-art deep architecture Learned Iterative Shrinkage-Thresholding Algorithm (LISTA),
                      leading to the reliable recovery of the signal under sample-wise varying model mismatch. Our
                      proposed network is also shown to outperform LISTA in compressive sensing problems under
                      sample-wise varying model mismatch.
                    </p>
                  </div>
                </div>
              </div>
            </li>
            <li>
              <div class="row">
                <div class="col-sm-2 abbr"> <abbr class="badge">Conference</abbr>
                </div>
                <div id="10.1109/ICASSP39728.2021.9414555" class="col-sm-8">
                  <div class="title">An ADMM Based Network for Hyperspectral Unmixing Tasks
                  </div>
                  <div class="author">
                    <em>C. Zhou</em>, and
                    <a href="https://scholar.google.co.uk/citations?user=Fmjz3bYAAAAJ&hl=en"
                      rel="external nofollow noopener" target="_blank">M. R. D. Rodrigues</a>
                  </div>
                  <div class="periodical"> in <em>IEEE International Conference on Acoustics, Speech and Signal
                      Processing (ICASSP)</em>, Toronto, ON, Canada, 2021, pp. 1870-1874, doi:
                    10.1109/ICASSP39728.2021.9414555.</div>

                  <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                    <a href="https://ieeexplore.ieee.org/abstract/document/9414555" class="btn btn-sm z-depth-0"
                      role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a
                      href="https://github.com/ChaoEdisonZhouUCL/UADMMNet" class="btn btn-sm z-depth-0" role="button"
                      rel="external nofollow noopener" target="_blank">Code</a>
                  </div>
                  <div class="abstract hidden">
                    <p>In this paper, we use algorithm unrolling approaches in order to design a new neural network
                      structure applicable to hyperspectral unmixing challenges. In particular, building upon a
                      constrained sparse regression formulation of the underlying unmixing problem, we unroll an ADMM
                      solver onto a neural network architecture that can be used to deliver the abundances of different
                      (known) endmembers given a reflectance spectrum. Our proposed network – which can be readily
                      trained using standard supervised learning procedures – is shown to possess a richer structure
                      consisting of various skip connections and shortcuts than other competing architectures. Moreover,
                      our proposed network also delivers state-of-the-art unmixing performance compared to competing
                      methods.
                    </p>
                  </div>
                </div>
              </div>
            </li>
          </ol>
          <h2 class="bibliography">2017</h2>
          <ol class="bibliography">
            <li>
              <div class="row">
                <div class="col-sm-2 abbr"> <abbr class="badge">Journal</abbr>
                </div>
                <div id="10.1109/TVT.2017.2726352" class="col-sm-8">
                  <div class="title">Symmetric Channel Hopping for Blind Rendezvous in Cognitive Radio Networks Based on
                    Union of Disjoint Difference Sets</div>
                  <div class="author"> X. J. Tan, <em>C. Zhou</em>, and J. Chen </div>
                  <div class="periodical"> in <em>IEEE Transactions on Vehicular Technology</em>, vol. 66, no. 11, pp.
                    10233-10248, Nov. 2017, doi: 10.1109/TVT.2017.2726352.</div>
                  <div class="periodical"> </div>
                  <div class="links"> <a href="https://ieeexplore.ieee.org/abstract/document/7976391"
                      class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener"
                      target="_blank">PDF</a> </div>
                </div>
              </div>
            </li>
          </ol>
        </div>
      </article>
    </div>
  </div>
  <footer class="fixed-bottom" role="contentinfo">
    <div class="container mt-0"> © Copyright 2024 Chao Zhou. Powered by <a href="https://jekyllrb.com/" target="_blank"
        rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio"
        rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a
        href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from
      <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>.
    </div>
  </footer>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"
    integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <script src="/assets/js/bootstrap.bundle.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js"
    integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js"
    integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js"
    integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js"
    integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script>
  <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script>
  <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script>
  <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script>
  <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script>
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>
  <script type="text/javascript">window.MathJax = { tex: { tags: "ams" } };</script>
  <script defer type="text/javascript" id="MathJax-script"
    src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script>
  <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script
    type="text/javascript">function progressBarSetup() { "max" in document.createElement("progress") ? (initializeProgressElement(), $(document).on("scroll", function () { progressBar.attr({ value: getCurrentScrollPosition() }) }), $(window).on("resize", initializeProgressElement)) : (resizeProgressBar(), $(document).on("scroll", resizeProgressBar), $(window).on("resize", resizeProgressBar)) } function getCurrentScrollPosition() { return $(window).scrollTop() } function initializeProgressElement() { let e = $("#navbar").outerHeight(!0); $("body").css({ "padding-top": e }), $("progress-container").css({ "padding-top": e }), progressBar.css({ top: e }), progressBar.attr({ max: getDistanceToScroll(), value: getCurrentScrollPosition() }) } function getDistanceToScroll() { return $(document).height() - $(window).height() } function resizeProgressBar() { progressBar.css({ width: getWidthPercentage() + "%" }) } function getWidthPercentage() { return getCurrentScrollPosition() / getDistanceToScroll() * 100 } const progressBar = $("#progress"); window.onload = function () { setTimeout(progressBarSetup, 50) };</script>
</body>

</html>